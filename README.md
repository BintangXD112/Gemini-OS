
# Gemini OS

Gemini OS is a web-based desktop environment simulation where the user interface for applications is dynamically generated by Google's Gemini API. It showcases the power of large language models to create interactive, stateful, and creative user experiences on the fly based on simple user interactions.

## ‚ú® Features

- **Dynamic UI Generation**: The core of the OS. Application interfaces are not pre-built but are generated in real-time by the Gemini model in response to user clicks.
- **Interactive Apps**: A suite of familiar desktop applications, including:
  - **üìù Notepad**: Create and edit text.
  - **üñºÔ∏è Photos**: View a gallery and generate new images using a text prompt powered by the Imagen model.
  - **üåê Web Browser**: A simulated web browser that can embed Google Search results.
  - **üéÆ Games**: A menu of simple, playable games (like Snake or Tic-Tac-Toe) generated as self-contained HTML and JavaScript.
  - **And more**: Documents, Calculator, Settings, Travel, etc.
- **Draggable Window**: The main application window can be moved around the desktop for a more realistic OS feel.
- **Stateful Experience**: An optional "Statefulness" mode caches the generated UI for previously visited states, allowing for instant navigation within an app session.
- **LLM-Powered Logic**: All application logic, layout, and content are determined by the LLM, guided by a sophisticated system prompt.

## üöÄ How It Works

The application operates on a simple yet powerful loop:

1.  **User Interaction**: The user clicks on an interactive element (an icon, a button, etc.) within the UI.
2.  **Data Capture**: React captures the interaction, packaging key details like the element's ID, type, and any associated value into an `InteractionData` object.
3.  **API Request**: This interaction data, along with the recent history of interactions and the current application context, is formatted into a prompt. This prompt is sent to the Gemini API.
4.  **Content Generation**: The Gemini model processes the prompt, understands the user's intent based on the interaction history and its instructions, and generates new HTML content for the application window.
5.  **UI Update**: The generated HTML is streamed back to the client. React then renders this new HTML, seamlessly updating the application's view to reflect the new state.

This cycle allows for an almost infinitely flexible and creative user interface, where the only limit is the LLM's ability to generate coherent HTML and JavaScript.

## üõ†Ô∏è Tech Stack

- **Frontend**: [React](https://react.dev/) with TypeScript
- **Styling**: [Tailwind CSS](https://tailwindcss.com/)
- **AI Model**: [Google Gemini API](https://ai.google.dev/) (`gemini-2.5-flash-preview-04-17`)
- **Image Generation**: [Google Imagen 3 Model](https://deepmind.google/technologies/imagen-2/) (`imagen-3.0-generate-002`)
- **Bundling/Imports**: Handled via `esm.sh` through an `importmap`.

## ‚öôÔ∏è Setup

To run this project, you need a Google Gemini API key.

1.  Obtain an API key from [Google AI Studio](https://aistudio.google.com/app/apikey).
2.  Set the `API_KEY` as an environment variable in the execution environment. The application is hardcoded to read `process.env.API_KEY`.
3.  Serve the `index.html` file using a local web server.

The application will not function without a valid API key.
